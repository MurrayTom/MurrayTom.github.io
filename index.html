<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yutao Mou</title>

  <meta name="author" content="Yutao Mou (牟宇滔)">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Yutao Mou (牟宇滔)
                  </p>
                  <p>I am a first-year PhD student at <a href="https://se.pku.edu.cn/kcl/">KCL Lab</a>, Peking University,
                    and supervised by professors <a href="https://se.pku.edu.cn/kcl/weiye/">Wei Ye</a> and Shikun Zhang. I received the Master and B.S. degree from Beijing University of Posts and Telecommunications, in 2024 and 2021.
                  </p>
                  </p>
                  <p> I have been working on building safe, reliable and scalable artificial intelligence systems. Currently, my research interests lie in two main areas:

                    **(1) Safety Evaluation and Red Teaming of Large Language Models (LLMs):**

                    We focus on building comprehensive safety evaluation benchmarks across various scenarios (e.g., text generation, code agents, multimodal tasks), designing jailbreak and automated red-teaming methods, and studying the interpretability of model vulnerabilities.

                    **(2) Post-Training and Safety Alignment of LLMs:**

                    Our goal is to incorporate safety-related data, reward signals, and training objectives into the post-training stage of LLMs to enhance safety without compromising general capabilities. We are particularly interested in safety alignment of large reasoning models, safety-oriented reward models, and the automated synthesis and data augmentation of safety fine-tuning data. In the future, we also plan to explore multimodal safety alignment.             
                  </p>
                  <p> Feel free to contact me for communication and collaboration.</p>
                  <p style="text-align:center">
                    <a href="yutao.mou@stu.pku.edu.cn">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=f71f5YkAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/MurrayTom">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:30%;max-width:30%">
                  <a href="images/photo2.jpg"><img style="width:80%;max-width:80%;object-fit: cover; "
                      alt="profile photo" src="images/photo2.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Publications</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/SaRO.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2504.09420">
                    <span class="papertitle">SaRO: Enhancing LLM Safety through Reasoning-based Alignment</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Yuxiao Luo, Shikun Zhang, Wei Ye
                  <br>
                  <em>ACL</em>, 2025 (Findings)
                  <br>
                  <a href="https://github.com/MurrayTom/SaRO">Code</a>
                  /
                  <a href="https://arxiv.org/abs/2504.09420">Paper</a>
                  <p>
                    In this study, we address the prevalent issue of shallow alignment in current LLM safety alignment methods by proposing the Safety-oriented Reasoning Optimization Framework (SaRO). 
                    SaRO introduces a System 2-style alignment to internalize a deliberative, slow-thinking reasoning approach, enabling models to reflect on safety policies more effectively. This framework enhances safety performance without compromising the general capabilities of the model.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/CoV-Eval.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2505.10494">
                    <span class="papertitle">Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye
                  <br>
                  <em>ACL</em>, 2025 (<span style="color:red; font-weight:bold;">CCF-A</span>)
                  <br>
                  <a href="https://github.com/MurrayTom/CoV-Eval">Code</a>
                  /
                  <a href="https://arxiv.org/abs/2505.10494">Paper</a>
                  <p>
                    In this paper, we construct a benchmark dataset named CoV-Eval, which encompasses various task types and covers a wide range of code security vulnerabilities. From the perspective of code security, 
                    we evaluate LLMs and various coding assistants, focusing on assessing the security vulnerabilities in code generated by LLMs, as well as their capabilities in vulnerability detection and repair.
                  </p>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/SG-Bench.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/de7b99107c53e60257c727dc73daf1d1-Abstract-Datasets_and_Benchmarks_Track.html">
                    <span class="papertitle">SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Shikun Zhang, Wei Ye
                  <br>
                  <em>NeurIPS</em>, 2024 (<span style="color:red; font-weight:bold;">CCF-A</span>)
                  <br>
                  <a href="https://github.com/MurrayTom/SG-Bench">Code</a>
                  /
                  <a href="https://arxiv.org/abs/2410.21965">Paper</a>
                  <p>
                    This paper introduces SG-Bench, a new benchmark for evaluating LLM safety, which pioneers the concept of safety generalization—assessing how variations in task and prompt types affect model safety. 
                    SG-Bench combines both generative and discriminative tasks and expands test data to evaluate the impact of prompt engineering and jailbreak attacks
                  </p>
                </td>
              </tr>
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/UEGP.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=uQEnx6FA5z">
                    <span class="papertitle">UEGP: Unified Expert-Guided Pre-training for Knowledge Rekindle</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Kexiang Wang, Jianhe Lin, Dehong Ma, Jun Fan, Daiting Shi, Zhicong Cheng, Gu Simiu, Dawei Yin, Weiran Xu
                  <br>
                  <em>NAACL findings</em>, 2024
                  <br>
                  <a href="https://openreview.net/forum?id=uQEnx6FA5z">Code</a>
                  /
                  <a href="https://openreview.net/forum?id=uQEnx6FA5z">Paper</a>
                  <p>
                    This paper first propose a new paradigm: knowledge rekindle, which aims to re-incorporate the fine-tuned expert model into the training cycle and break through the performance upper bounds 
                    of experts without introducing additional annotated data. Then we further propose a unified expert-guided pre-training (UEGP) framework for knowledge rekindle. 
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/DPL.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://aclanthology.org/2023.acl-long.538/">
                    <span class="papertitle">Decoupling Pseudo Label Disambiguation and Representation Learning for Generalized Intent Discovery</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Xiaoshuai Song*, Keqing He*, Chen Zeng, Pei Wang, Jingang Wang, Yunsen Xian, Weiran Xu
                  <br>
                  <em>ACL</em>, 2023 (<span style="color:red; font-weight:bold;">CCF-A</span>)
                  <br>
                  <a href="https://github.com/songxiaoshuai/DPL">Code</a>
                  /
                  <a href="https://aclanthology.org/2023.acl-long.538/">Paper</a>
                  <p>
                    This paper focuses on the generalized intent discovery task, and proposes a decoupled prototype learning framework (DPL) 
                    to decouple pseudo label disambiguation and representation learning. 
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/KCOD.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://aclanthology.org/2022.emnlp-main.98/">
                    <span class="papertitle">Watch the Neighbors: A Unified K-Nearest Neighbor Contrastive Learning Framework for OOD Intent Discovery</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Keqing He*, Pei Wang, Yanan Wu, Jingang Wang, Wei Wu, Weiran Xu
                  <br>
                  <em>EMNLP</em>, 2022 (<span style="color:red; font-weight:bold;">CCF-B</span>)
                  <br>
                  <a href="https://github.com/myt517/KCOD">Code</a>
                  /
                  <a href="https://aclanthology.org/2022.emnlp-main.98/">Paper</a>
                  <p>
                    This paper focuses on new intent discovery and clustering task, and propose a unified K-nearest neighbor contrastive learning framework to discover OOD intents.
                    Specifically, we design a novel K-nearest neighbor contrastive learning objective (KCL) for in-domain pre-training, and a hard negative mining strategy for 
                    self-supervised representation learning on unlabeled out-of-domain data.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/UniNL.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://aclanthology.org/2022.emnlp-main.494/">
                    <span class="papertitle">UniNL: Aligning Representation Learning with Scoring Function for OOD Detection via Unified Neighborhood Learning</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Pei Wang*, Keqing He*, Yanan Wu, Jingang Wang, Wei Wu, Weiran Xu
                  <br>
                  <em>EMNLP</em>, 2022 (short paper)
                  <br>
                  <a href="https://github.com/Yupei-Wang/UniNL">Code</a>
                  /
                  <a href="https://aclanthology.org/2022.emnlp-main.494/">Paper</a>
                  <p>
                    This paper focuses on out-of-domain (OOD) intent detection task, and propose a unified neighborhood learning framework (UniNL) to detect OOD intents.
                    propose a unified K-nearest neighbor contrastive learning framework to discover OOD intents. Specifically, we design a K-nearest neighbor contrastive learning objective for
                    training and introduce a KNN-based scoring function for confidence estimation. We aim to align training objective with confidence function in inference stage.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/GID.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://aclanthology.org/2022.coling-1.59/">
                    <span class="papertitle">Generalized Intent Discovery: Learning from Open World Dialogue System</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Keqing He*, Yanan Wu, Pei Wang, Jingang Wang, Wei Wu, Yi Huang, Junlan Feng, Weiran Xu
                  <br>
                  <em>COLING</em>, 2022 (<span style="color:red; font-weight:bold;">CCF-B</span>)
                  <br>
                  <a href="https://github.com/myt517/GID_benchmark">Code</a>
                  /
                  <a href="https://aclanthology.org/2022.coling-1.59/">Paper</a>
                  <p>
                    This paper defines a new task, Generalized Intent Discovery (GID), which aims to extend an IND intent classifier to an open-world intent set including IND 
                    and OOD intents. We hope to simultaneously classify a set of labeled IND intent classes while discovering and recognizing new unlabeled OOD types incrementally. We construct
                    three public datasets for different application scenarios and propose two kinds of frameworks, pipeline-based and end-to-end for future work.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/DKT.jpg' width=100%>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://aclanthology.org/2022.acl-short.6/">
                    <span class="papertitle">Disentangled Knowledge Transfer for OOD Intent Discovery with Unified Contrastive Learning</span>
                  </a>
                  <br>
                  <strong>Yutao Mou</strong>*, Keqing He*, Yanan Wu*, Zhiyuan Zeng, Hong Xu, Huixing Jiang, Wei Wu, Weiran Xu
                  <br>
                  <em>ACL</em>, 2022 (short paper)
                  <br>
                  <a href="https://github.com/myt517/DKT">Code</a>
                  /
                  <a href="https://aclanthology.org/2022.acl-short.6/">Paper</a>
                  <p>
                    Discovering Out-of-Domain (OOD) intents is essential for developing new skills in a task-oriented dialogue system. The key challenge is how to transfer prior IND knowledge to OOD clustering.
                    This paper proposes a decoupled knowledge transfer framework for new intent discovery and clustering, which unifies the two-stage learning process of 
                    in-domain and out-of-domain data into instance discrimination and clustering discrimination tasks and bridges the gap between in-domain and out-of-domain data. 
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <!-- internship -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Internships</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <ul>
            <!-- <li>
              <p>Shanghai AI Laboratory</p>
            </li> -->
            <li>
              <p style="line-height: 1.5;"><b>Sensetime Research</b>, Beijing, China. June 2023 - December 2023.
              </br>
              Research Internship, working on Large Language Model and Hallucination Correction.
              </p>
            </li>
            <li>
              <p style="line-height: 1.5;" ><b>Baidu Inc.</b>, Beijing, China. December 2022 - May 2023.
              </br>
              Research Internship, focusing on search re-ranking and pre-training.
            </p>
            </li>
          </ul>

          <!-- honors and awards -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Selected Honors</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <ul>
            <li>
              <p>China National Scholarship. Ministry of Education of P.R. China. 2023.</p>
            </li>
            <li>
              <p>Excellent Graduate. Beijing University of Posts and Telecommunications. 2023.</p>
            </li>
            <li>
              <p>Schlumberger Enterprise Scholarship. Beijing University of Posts and Telecommunications. 2022.</p>
            </li>
            <li>
              <p>1st Award on SereTOD Challenge 2022 track 2, EMNLP 2022</p>
            </li>
            <li>
              <p>Excellent Graduate. Beijing University of Posts and Telecommunications. 2022.</p>
            </li>
            <li>
              <p>China National Scholarship. Ministry of Education of P.R. China. 2020.</p>
            </li>
            <li>
              <p>First Prize in National College Student Mathematics Competition. Chinese Mathematics League. 2018. </p>
            </li>
          </ul>

          <br>
          <hr>

          <!-- service -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Service</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <ul>
            <li>
              <p>Reviewer: EMNLP2022, ACL2023, EMNLP2023, ARR</p>
            </li>
          </ul>

          <br>
          <hr>

        </td>
      </tr>
    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">
            Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's
              website</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>
